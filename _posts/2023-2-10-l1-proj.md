---
title: 'Projection onto the L1-Norm Ball'
date: 2023-2-10
permalink: /posts/l1-proj
toc: true
---
In this post we will discuss a frequently visited problem in convex optimization: projection onto the $\ell_1$-norm ball. I think this is a great example to understand the concepts of duality and subgradients and the phenomenon called *sparsity*, where the solution to a problem contains mostly zeros, and only some remain "activated."

## The Problem

Suppose we have a vector $a \in \mathbb{R}^n$ and want to find another vector $x$ in an $\ell_1$-norm ball such that the distance between $a$ and $x$ is the smallest possible. In other words, we seek to solve the following problem

$$
\begin{align}
    \begin{aligned}
        \min_{x} \quad & \left\{ f(x) = \frac{1}{2} \lVert x - a \rVert_2^2 \right\} \\
        \text{such that} \quad &  \lVert x \rVert_1 \leq \kappa.
    \end{aligned}
    \label{eq:primal}
\end{align}
$$

The constraint $\lVert x \rVert_1 \leq \kappa$ denotes the $\ell_1$-norm ball of radius $\kappa > 0$ (that is, all the points whose $\ell_1$ norm is at most $\kappa$) and $f(x)$ is the primal objective function.

Does this problem have a closed-form solution? Yes, but not always. Like all projection problems, if $a$ is already in the convex set ($\lVert a \rVert_1 \leq \kappa$) then the solution is simply $x = a$, and we are done. Otherwise, we will need to approximate the solution.

<p align="center">
    <img src="/files/l1_proj_figs/l1_gif.gif" title="L1 projection">
</p>

In the above figure, we see an example in $n=2$ dimensions. The black square (containing all points on and within its boundaries) represents the $\ell_1$-norm ball of radius $\kappa = 1$. The center of the blue circle, in red, is the vector $a$ and the radius of the circle is the smallest distance from $a$ to the $\ell_1$-norm ball.

## Duality

It is easy to see that $\eqref{eq:primal}$ is a convex optimization problem as its objective and constraint are both convex. Note that in this case, $x = 0$ is a strictly feasible solution, which means, by Slater's condition, strong duality holds. We therefore will aim to solve $\eqref{eq:primal}$ by maximizing its dual function. Let $\gamma \geq 0$ be the dual variable; the Lagragian is

$$
\begin{align*}
    L(x, \gamma) = \frac{1}{2} \lVert x - a \rVert_2^2 + \gamma (\lVert x \rVert_1 - \kappa).
    \label{eq:lagrangian}
\end{align*}
$$

Finding the dual objective function requires us to minimize $L(x, \gamma)$ with respect to $x$. Notice that we can rewrite the Lagrangian as

$$
\begin{align*}
    L(x, \gamma) = - \kappa \gamma +  \sum_{i=1}^{n} \left( \frac{1}{2} (x_i - a_i)^2 + \gamma \left| x_i \right| \right),
    \label{eq:lagrangian_as_sum}
\end{align*}
$$

where the subscript $i$ denotes the $i$th element of a vector. If we let

$$
\begin{align*}
    s_i(x_i, \gamma) = \frac{1}{2} (x_i - a_i)^2 + \gamma \left| x_i \right|,
    \label{eq:si}
\end{align*}
$$ 

then minimizing $L(x, \gamma)$ with respect to $x$ means to minimize each $s_i(x_i, \gamma)$ with respect to $x_i$. Fortunately, the problem $\min_{x_i} s_i(x_i, \gamma)$ has a unique and closed-form solution:

$$
\begin{align}
    x_i(\gamma) = 
    \begin{cases}
        a_i - \gamma & \text{if} \quad a_i > \gamma \\
        0            & \text{if} \quad - \gamma \leq a_i \leq \gamma \\
        a_i - \gamma & \text{if} \quad a_i < \gamma.
    \end{cases}
    \label{eq:threshold_si}
\end{align}
$$

This is is called the *soft thresholding operator* for $\gamma$. Equation $\eqref{eq:threshold_si}$ shows us how to convert a dual solution $\gamma$ to a primal solution $x$. Now, if we let $s_i^*(\gamma) = \min_{x_i} s_i(x_i, \gamma) = s_i(x_i(\gamma), \gamma)$, the dual objective is

$$
\begin{align*}
    g(\gamma) = \min_{x} L(x, \gamma) =  - \kappa \gamma + \sum_{i=1}^{n} s_i^*(\gamma).
\end{align*}
$$

We know that $g$ is a concave function by design. Furthermore, since the solution to $\min_{x_i} s_i(x_i, \gamma)$ is unique for every $\gamma \geq 0$, by [Danskin's theorem](https://en.wikipedia.org/wiki/Danskin%27s_theorem), each $s_i^*$ is differentiable, which makes $g$ differentiable as well. We can easily verify that the derivative of $g$ is

$$
\begin{align*}
    \frac{d}{d\gamma}g(\gamma) = \min_{x} L(x, \gamma) =  - \kappa + \sum_{i=1}^{n} \max(\left| a_i \right| - \gamma, 0).
\end{align*}
$$

<details>
    <summary><b>Proof.</b></summary>
    <div style="padding-left:2em; padding-right:2em">
        <br/>
        It only remains to be shown that $\frac{d}{d\gamma} s_i^*(\gamma) = \max(\left| a_i \right| - \gamma, 0)$. To see why, note that

        $$
        \begin{align*}
            s_i^*(\gamma) = s_i(x_i(\gamma), \gamma) = \frac{1}{2} (x_i(\gamma) - a)^2 + \gamma (x_i(\gamma)).
        \end{align*}
        $$

        It is easy to show that, by $\eqref{eq:threshold_si}$,
        $$
        \begin{align*}
            (x_i(\gamma) - a)^2 = \min(\left| a_i \right|, \gamma)^2,
        \end{align*}
        $$
        and
        $$
        \begin{align*}
            (x_i(\gamma) - a)^2 = \max(\left| a_i \right| - \gamma, 0)^2.
        \end{align*}
        $$
        Now we consider two cases of $\gamma$. First, if $\gamma \leq |a_i|$, we have $s_i^*(\gamma) = - \frac{1}{2} \gamma^2 + |a_i| \gamma$, which gives its derivative equal to $|a_i| - \gamma$. Second, if if $\gamma > |a_i|$, $s_i^*(\gamma) = 0$. Either way, $\frac{d}{d\gamma} s_i^*(\gamma) = \max(|a_i| - \gamma, 0)$.
    </div>
</details>

So far we have been able to find the dual function $g(\gamma)$ and its derivative $g'(\gamma)$. Now we will explore a method to maximize $g(\gamma)$ and recover the primal optimal solution.

## Optimizing the Dual Function

As a reminder, we will aim to solve the problem

$$
\begin{align}
    \max_{\gamma} g(\gamma) \quad \text{such that} \quad \gamma \geq 0.
    \label{eq:dual}
\end{align}
$$

Since $g$ is concave and differentiable, we can aim to maximize it by using a hill-climbing algorithm such as gradient ascent with backtracking line search. Below is an example dual function and its derivative at various values of $\gamma$.

<p align="center">
    <img src="/files/l1_proj_figs/l1_dual_gif.gif" title="L1 projection, dual function">
</p>

In this post we will solve this problem using a different method called [bisection](https://en.wikipedia.org/wiki/Bisection_method). The aim here is to set the derivative to zero and solve for $\gamma$. In other words, we seek the solution to $g'(\gamma) = 0$. The bisection method requires us to have a range $[\gamma_{\min}, \gamma_{\max}]$ in which we are sure the optimal solution $\gamma^*$ lies.

First, since $\gamma^*$ must be feasible, we set $\gamma_{\min} = 0$. To find an upper bound, note that since the optimal objective value for Problem $\eqref{eq:primal}$ must be non-negative, and strong duality holds, the optimal value for Problem $\eqref{eq:dual}$ is also non-negative. This implies that

$$
\begin{align*}
    - \kappa \gamma^* + \sum_{i=1}^{n} s_i(x_i(\gamma^*), \gamma^*) \geq 0.
\end{align*}
$$

Therefore,

$$
\begin{align*}
    \gamma^* & \leq \frac{1}{\kappa} \sum_{i=1}^{n} s_i(x_i(\gamma^*), \gamma^*)
     \leq \frac{1}{\kappa} \sum_{i=1}^{n} s_i(0, \gamma^*) 
    = \frac{1}{\kappa} \sum_{i=1}^{n} \frac{a_i^2}{2}
     = \frac{1}{2 \kappa} \lVert a \rVert_2^2,
\end{align*}
$$

where the second inequality is due to the fact that $$x_i(\gamma^*)$$ is the minimizer if $s_i(x, \gamma^*)$. So an upper bound we can set for $$\gamma^*$$ is $$\gamma_{\max} = \frac{1}{2 \kappa} \lVert a \rVert_2^2$$.

Now that we know $$\gamma^*$$ is in between $\gamma_{\min} = 0$ and $$\gamma_{\max} = \frac{1}{2 \kappa} \lVert a \rVert_2^2$$, the bisection method works as follows. First, let $\gamma = (\gamma_{\min} + \gamma_{\max}) / 2$. If the sign of $g'(\gamma)$ is the same as that of $g'(\gamma_{\min})$, then $\gamma_{\min}$ is updated to $\gamma$. Otherwise, $\gamma_{\max}$ is updated to $\gamma$. It is simple as that! The method is also guaranteed to converge, as after each iteration, the length of the interval $[\gamma_{\min}, \gamma_{\max}]$ is reduced by half.

## Implementation

Here is a simple Python implementation of the bisection method for maximizing the dual objective. First we define a few functions.

```py
def primal_fn(x, a):
    return 0.5 * np.sum((x - a) ** 2)

# Vectorize the computation of s_i(x, gamma)
def s(x, gamma, a):
    return 0.5 * (x - a) ** 2 + gamma * np.abs(x)

def x_gamma(gamma, a):
    sol = np.zeros_like(a)
    idx = a > gamma
    sol[idx] = a[idx] - gamma
    idx = a < - gamma
    sol[idx] = a[idx] + gamma
    return sol

def dual_fn(gamma, kappa, a):
    x = x_gamma(gamma, a)
    return - kappa * gamma + np.sum(s(x, gamma, a))

def dual_grad(gamma, kappa, a):
    return - kappa + np.sum(np.maximum(np.abs(a) - gamma, 0))
```

Then, the bisection method is straightforward. We can let the iterations run until difference $\gamma_{\max} - \gamma_{\min}$  reaches a pre-defined error $\varepsilon$, at which point the derivative should be close enough to $0$.

```py
def bisection(a, kappa, eps=1e-5):
    gamma_min, gamma_max = 0, (1 / (2 * kappa)) + np.sum(a ** 2)
    # Run until gamma_max and gamma_min are the same
    while gamma_max - gamma_min > eps:
        gamma = (gamma_max + gamma_min) / 2
        grad = dual_grad(gamma, kappa, a)
        if grad < 0: 
            gamma_max = gamma
        else:
            gamma_min = gamma
    return gamma
```

The two plots above are produced using the following code.

```py
# Point to be projected
a = np.array(1.1, 1.2)
# Radius of the ell_1 norm ball
kappa = 1
# Find approximate solution to the dual problem
dual_solution = bisection(a, kappa, eps=1e-5)
# Convert to the primal solution
primal_solution = x_gamma(dual_solution, a)
```

## Sparseness of the Solution

Projection onto the $\ell_1$-norm ball has an interesting characteristics: in high dimensions, the optimal solution has a tendency to be *sparse*, which means most of its elements are driven to zero. To see why, let's try an example.

```py
>>> np.random.seed(100)
>>> a = np.random.randn(100)
>>> dual_solution = bisection(a, kappa=1, eps=1e-10)
>>> primal_solution = x_gamma(dual_solution, a)
>>> print(np.count_nonzero(primal_solution))
5
```

In this example, I generated the $100$-dimensional vector $a$ by independently sampling $100$ values from the standard normal distribution. After projection, the solution only contains $5$ non-zero values. Only $5$ out of $100$ elements remain non-zero! (Be careful: I set $\epsilon$ to be very small but it's probably better to check equality using `np.allclose` to compare two floating point numbers.)

You may ask, "What's the significance of this?" The tendency to drive most variables to zero forms the success of the [lasso](https://en.wikipedia.org/wiki/Lasso_(statistics)) method. Imagine you are performing a regression analysis with many, many variables. While $\ell_2$ is a more popular regularizer you may choose, $\ell_1$ may be preferred if you like to assess features' importance: those with non-zero coefficients tend to be very few, and represent the most important features you may want to keep during feature selection. A final note is that the formulation of lasso regression is not exactly the problem discussed in this method: the variable has to go through a linear transformation in lasso. However, observations remain similar.

## Resources

1. Ryan Tibshirani's [lectures on convex optimization](https://www.stat.cmu.edu/~ryantibs/convexopt/), specifically those on duality and proximal gradient descent.
2. [Convex Optimization](https://web.stanford.edu/~boyd/cvxbook/bv_cvxbook.pdf) by Boyd and Vandenberghe.